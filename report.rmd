---
title: S&P 500 Price Change Predictors
author:
- Andy Barnes
- Ryan Leveille
- Tong Sun
- Jared Turner
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
- \usepackage{amssymb}
- \usepackage{amsthm}
- \usepackage{graphicx}
- \newcommand{\Lim}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \lim_{#1}\;$}}}
- \makeatletter\renewcommand*{\fps@figure}{H}\makeatother
output:
 pdf_document:
  latex_engine: xelatex
linkcolor: blue
---

```{r global.options, include = TRUE, echo=FALSE}
library(kableExtra)
knitr::opts_chunk$set(
    cache       = TRUE,     # if TRUE knitr will cache the results to reuse in future knits
    fig.width   = 5.5,       # the width for plots created by code chunk
    fig.height  = 4,       # the height for plots created by code chunk
    fig.align   = 'center', # how to align graphics in the final doc. 'left', 'right', 'center'
    fig.path    = 'figs/',  # file path to the directory where knitr shall store the graphics files
    echo        = TRUE,     # in FALSE knitr will not display code in the code chunk above it's results
    message     = TRUE,     # if FALSE knitr will not display any messages generated by code
    strip.white = TRUE,     # if FALSE knitr will not remove white spaces at the beg or end of code chunk
    warning     = FALSE)    # if FALSE knitr will not display any warning messages in the final document
```

# Project Scope

## S&P 500

The Standard & Poor's 500, often abbreviated as the S&P 500, or just the S&P, is an American stock market index based on the market capitalizations of 500 large companies having common stock listed on the New York Stock Exchange (NYSE) or Nasdaq, Inc (NASDAQ). The NYSE and NASDAQ are the American stock exchanges where the stocks that make up the S&P 500 are traded. Market capitalization (market cap) is the market value of a publicly traded company's outstanding shares. Market capitalization is equal to the share price multiplied by the number of shares outstanding. As outstanding stock is bought and sold in public markets, capitalization could be used as an indicator of public opinion of a company's net worth and is a determining factor in some forms of stock valuation. The reason that we chose to use the S&P 500 for our companies is that it is a very broad and diversified index that includes companies from many different industries. The S&P 500 is one of the most commonly followed equity indices, and many consider it one of the best representations of the U.S. stock market, and a bellwether for the U.S. economy. The share prices for each company within the S&P 500 change daily (during trading days) based on trading interest. A share price is the price of a single share of a company, derivative or other financial asset. The share price is the highest amount someone is willing to pay for the stock, or the lowest amount that it can be bought for.

## Time Frame

Our project is going to analyze the companies within the S&P 500 over a 7 year period. This period is going to be from 1/01/2011-12/31/2017.

Approach:

Due to the volatility of the stock market and how the data can sometimes be very misleading depending upon the time frame which you choose to analyze the data from, we are going to approach this project with the intention of minimizing any major outliers for our response variable (share price).

For example, if we were to randomly select some date in 2011 and observe the share price for Microsoft it could be $50 per share. Likewise if we took another random date in 2011 to observe the price of Microsoft it could be $25 per share, perhaps even just a week before or after the price was at $50 per share. Furthermore, when we analyze the response variable in 2017 it could be $50 or $25, depending on the time frame you select for the observation.

Therefore, the way that we will make sure that we do not misrepresent our response variable and by keeping the project within the scope of our class we will be taking the average of the share price for each company within the S&P 500 for the years 2011 and 2017. The 5 years in between (2012, 2013, 2014, 2015, 2016) will allow plenty of time for our response variable to change based on our predictor variables.

Another reason why we want to calculate the average share price for each company by year is because our predictor variables will be yearly as well.

The S&P 500 is based on market cap and some companies will grow in size or fall in size so we will be using companies that were in the S&P 500 starting on January 1, 2011, and are still in the S&P 500 on December 31, 2017. As of now, we have 476 companies out of 500 that are still within the S&P 500 to analyze.

## Response Variable

`Price.ch`: Our response variable is going to be the share price of each company within the S&P 500. We are going to take the average share price for 2011 and the average share price for 2017 and then calculate the percent difference for each company.

## Predictor Variables

We have multiple variables that we are going to use as our predictor variables. These variables have been chosen based on what what we think investors use to analyze a company before making an investment. Also, some other potential variables' data is incomplete or missing so we choose variables that were best for the scope of the project.

Our goal with this project is to find the predictor variables that have the biggest impact on our response variable (share price).

All of our variables are going to be using their percent change in yearly unit during our time period of 2011-2017. We will start with the predictor variables' 2011 observations and end with the predictor variables' 2017 observations. We chose this time frame because it gave us our yearly data of 2011, a 5 year time frame, then our yearly data of 2017.

1. `EPS`: Earnings per share (EPS) is the portion of a company's profit allocated to each share of common stock. Earnings per share serves as an indicator of a company's profitability.

2. `Div`: A dividend is a payment made by a corporation to its shareholders, usually as a distribution of profits. When a corporation earns a profit or surplus, the corporation is able to re-invest the profit in the business and pay a proportion of the profit as a dividend to shareholders.

3. `BV`: Book value per share indicates the book value (or accounting value) of each share of stock. Book value is a company's net asset value, which is calculated by total assets minus intangible assets and liabilities. An easy way to think of book value per share is what is the expected value of the company.

4. `RoA`: The return on assets shows the percentage of how profitable a company's assets are in generating revenue.

5. `RoE`: Return on equity is a measure of the profitability of a business in relation to the book value of shareholder equity, also known as net assets or assets minus liabilities. ROE is a measure of how well a company uses investments to generate earnings growth.

6. `RoIC`: Return on capital (ROC), or return on invested capital(ROIC), is a ratio used in finance, valuation and accounting, as a measure of the profitability and value-creating potential of companies after taking into account the amount of initial capital invested.

7. `DE`: Debt/Equity (D/E) Ratio, calculated by dividing a company's total liabilities by its stockholders' equity, is a debt ratio used to measure a company's financial leverage. The D/E ratio indicates how much debt a company is using to finance its assets relative to the value of shareholders' equity.

8. `Rev`: Revenue is the income that a business has from its normal business activities, usually from the sale of goods and services to customers.


# The Data

Our data looks at the $476$ stocks in in the S&P 500 today with data dating back to 2011. Each variable is given as the percent change in yearly value or average value from 2011 to 2017. The first $6$ rows of data are as follows


```{r echo=FALSE}
load("linear_project_data_plot_cor.Rda")
colnames(full_data) <- c("Co.", "Price.ch", "EPS", "Div", "BV", "RoA", "RoE", "RoIC", "DE", "Rev")
x <- head(full_data)
knitr::kable(x[,1:10], format="markdown", digits=4)
```
from this we can obtain the following correlation matrix.

```{r echo=FALSE}
cor.matrix <- cor(full_data[,-1], use="complete.obs")
knitr::kable(cor.matrix[,1:9], format="markdown", digits=4)
```

We see that there is strong correlation between `RoA` and `EPS`, there is some correlation between `Rev` and `BV`.

```{r , echo=FALSE, fig.cap="\\label{fig:figs}Scatterplot of raw data."}
plot(full_data[,-1], pch=20)
```

# Why we chose this data

We chose this project due to the vast amounts of data that the stock market encompasses. The stock market is a very broad topic and this project can be applied to many different situations.

With our project we hope to find which predictor variables affect the response variable (share price) the most. We are excited to see what our models come up with. The findings will be interesting as there are many different theories as to what is the most important predictor variables for a companies share price.

# Data preprocessing

Before formulating our model, we cleaned our data by filling in missing values. For the predictor variable `Div`, missing values were assumed to be $0$, this is because dividends other than $0$ are usually reported and recorded. For all other predictors, missing values were filled in with the mean among all observations for that data. After our data was cleaned we have the following correlation matrix and plot.

```{r echo=FALSE}
clean_data <- read.table("clean_data.csv", header=T, sep=",")
clean_data <- clean_data[,-1]
colnames(clean_data) <- c("Price.ch", "EPS", "Div", "BV", "RoA", "RoE", "RoIC", "DE", "Rev")
```

```{r, echo=FALSE}
cor.matrix.cleaned <- cor(clean_data)
y <- cor.matrix.cleaned
knitr::kable(y[,1:9], format="markdown", digits=4)
```
```{r, echo=FALSE, fig.cap="\\label{fig:figs}Scatterplot of clean data."}
plot(clean_data, pch=20)
```
\newpage

By looking at the scatterplot, there are potential linear relationships between `RoA` and both `EPS` and `RoE`. The correlation matrix and heat map confirm that `RoE` and `EPS` are highly correlated.

```{r echo=FALSE, fig.cap="\\label{fig:figs}Heat map of correlation matrix for cleaned data, darker shades correspond to greater correlation."}
library(RColorBrewer)
heatmap(cor.matrix.cleaned, col=brewer.pal(9,"Greys"), cexRow = 0.7, cexCol = 0.7,
        Rowv = NA, symm = T, reorderfun = NULL, margins = c(8,8), main="Correlation of cleaned data")
```

# Our Model

We will formulate a simple linear model, where our response, `Price.ch`, is a linear combination of our predictors

\begin{equation}
\tag*\*{}
\widehat{\text{Price.ch}_{i_{}}} = \beta_0 + \beta_1 \text{EPS}_{i_{}} + \beta_2 \text{Div}_{i_{}} + \beta_3 \text{BV}_{i_{}} + \beta_4 \text{RoA}_{i_{}} + \beta_5 \text{RoE}_{i_{}} + \beta_6 \text{RoIC}_{i_{}} + \beta_7 \text{DE}_{i_{}} + \beta_8 \text{Rev}_{i_{}} + \epsilon_i
\end{equation}

where $\epsilon_i \sim^{\text{iid}} N(0, \sigma^2)$. Where $\sigma^2$ is the population variance. Therefore we make the following assumptions for our model

1. Observations are indepent indentically distributed (iid), as is error, $\epsilon_i$.
2. Our response is normally distributed with mean $0$ and variance $\sigma^2$


After formulating our model, we fit our data to this model using R. The summary is as follows.

```{r, echo=FALSE, fig.width=8, fig.height=5}
full.model <- lm(Price.ch ~ ., data = clean_data)
summary(full.model)
rsq <- summary(full.model)$r.squared
```

Therefore our fitted model, with point estimates, of the parameters $\beta_0,..., \beta_8$, is given by

\begin{equation}
\tag*\*{}
\widehat{\text{Price.ch}_{i_{}}} = 0.935 + 0.004 \text{EPS}_{i_{}} + 0.047 \text{Div}_{i_{}} + 0.003 \text{BV}_{i_{}} + 0.009 \text{RoA}_{i_{}} + 0.001 \text{RoE}_{i_{}} + 0.052 \text{RoIC}_{i_{}} + 0.019 \text{DE}_{i_{}} + 0.548 \text{Rev}_{i_{}} + \epsilon_i
\end{equation}

Immediately we see that with such a small p-value, $2.2 \times 10^{-16}$, our model is significant. We also see that there are two predictors displaying initial significance, `Div` and `Rev`. However, in addition to our model having an R-squared of $`r rsq`$, indicating that only about $30\%$ of variation in our response is explained by our predictors, the following diagnostic plots challenge our assumptions.

```{r, echo=FALSE, fig.cap="\\label{fig:figs}Errors vs fitted values (Left) challenges iid error terms. While QQ Plot (Right) challenges the normality of our response."}
par(mfrow=c(1,2))
plot(full.model, c(1,2))
```
Additionally we can see that the histogram of our response values is skewed right, further challenging the normality of our response and indicating outliers.


```{r echo=FALSE, fig.cap="\\label{fig:figs}Histogram of response, `Price.ch`, skewness suggests outliers."}
hist(clean_data$Price.ch, main="", xlab="Price.ch")
```

## Checking for outliers.

In hopes of improving our model, we will set out to find a small subset of outliers we can throw out to improve our model. Our initial goal was to raise our R-squared value to at least $0.5$ with the hopes that this would help the distribution of our errors as well as the normality of our response. We wrote a script to this automatically and were able to raise our R-squared above $0.5$ by dropping $29$ observations. However, the question of whether this affects the validity of our model is a perfectly legitimate one.

## Justification for dropping outliers

It is generally not a good idea to drop a significant number of outliers without justification. However, given our knowledge of the market, there are two primary reasons that we believe dropping these outliers do not affect the objective of our model:

1. We are only dropping $`r round(2900/length(clean_data$Price.ch), 2)`\%$ of our data set, which is generally considered acceptable.

2. The stock market is very volatile and is littered with extreme cases. Our predictors are very basic and most extreme cases will likely be correlated with other factors outside the scope of this project.

3. We are studying the SP500 as a subset of popular stocks, but it also gives us insight into the population of all stocks. The SP500 is likely not representative of the population of all stocks. A random subset of 500 stocks from all stocks is more likely to contain a smaller percentage of these extreme observations. In the worst case dropping a small subset of outliers may actually help correct for this, making our sample more representative of the population of all stocks.

Our objective is exploratory in nature and we are not expecting to attain any predictive power from this model. We are only interested in which predictors are significant for most cases. We feel that this model, even with the outliers dropped, is still realistic in this regard.

## Final model

We now look assess this subset of our original data, with the outliers withdrawn. We fit this data to our original model using R to obtain the following summary.

```{r, echo=FALSE}
final_data <- read.table("clean_data_drop_v2.csv", header=T, sep=",")
final_data <- final_data[,-1]
colnames(final_data) <- c("Price.ch", "EPS", "Div", "BV", "RoA", "RoE", "RoIC", "DE", "Rev")
final.lm <- lm(Price.ch~., data=final_data)
summary(final.lm)
```
We now have an R-squared of $0.5061$, indicating that approximately $51\%$ of the variation in our response can be explained by our predictors. Additionally the p-value of our model remained the same, indicating significance of our overall model. However, we now show four initially significant predictors, `Div`, `BV`, `RoIC`, and `Rev`. After generating the same diagnostic plots as before we see improve, albeit not perfection, which is hardly ever to be expected from real world data.


```{r, echo=FALSE, fig.cap="\\label{fig:figs}Both the plot of errors vs fitted values (Left) and QQ Plot (Right) show improvement."}
par(mfrow=c(1,2))
plot(final.lm, c(1,2))
```

However, with these improvements we felt comfortable moving forward with our model and all of its assumptions.

Since not all predictors exihibited significance, we proceeded to reduce our model using R's built in `step` function. This function minimizes an information criteron AIC, which in effect improves model fit and reduces complexity. The output summary of this process and the resulting reduced model is as follows.

```{r, echo=FALSE}
final.lm.red <- step(final.lm)
summary(final.lm.red)
```

Our reduced model is thus given by


\begin{equation}
\tag*\*{}
\widehat{\text{Price.ch}_{i_{}}} = \beta_0 + \beta_1 \text{Div}_{i_{}} + \beta_2 \text{BV}_{i_{}} + \beta_3 \text{RoIC}_{i_{}} + \beta_4 \text{Rev}_{i_{}} + \epsilon_i
\end{equation}

where $\epsilon_i \sim^{\text{iid}} N(0, \sigma^2)$. Our reduced model carries the same assumptions as our original model. The model with the point estimations of our parameters is given by


\begin{equation}
\tag*\*{}
\widehat{\text{Price.ch}_{i_{}}} = 0.785 + 0.072 \text{Div}_{i_{}} + 0.025 \text{BV}_{i_{}} + 0.109 \text{RoIC}_{i_{}} + 0.479 \text{Rev}_{i_{}} + \epsilon_i.
\end{equation}



